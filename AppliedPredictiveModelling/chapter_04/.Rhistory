data(GermanCredit)
```{r}
library(e1071)
library(ggplot2)
library(caret)
library(plyr)
data(GermanCredit)
################################################################################
################################################################################
### R code from Applied Predictive Modeling (2013) by Kuhn and Johnson.
### Copyright 2013 Kuhn and Johnson
### Web Page: http://www.appliedpredictivemodeling.com
### Contact: Max Kuhn (mxkuhn@gmail.com)
###
### Chapter 4: Over-Fitting and Model Tuning
###
### Required packages: caret, doMC (optional), kernlab
###
### Data used:
###
### Notes:
### 1) This code is provided without warranty.
###
### 2) This code should help the user reproduce the results in the
### text. There will be differences between this code and what is is
### the computing section. For example, the computing sections show
### how the source functions work (e.g. randomForest() or plsr()),
### which were not directly used when creating the book. Also, there may be
### syntax differences that occur over time as packages evolve. These files
### will reflect those changes.
###
### 3) In some cases, the calculations in the book were run in
### parallel. The sub-processes may reset the random number seed.
### Your results may slightly vary.
###
################################################################################
################################################################################
### Section 4.6 Choosing Final Tuning Parameters
library(caret)
data(GermanCredit)
## First, remove near-zero variance predictors then get rid of a few predictors
## that duplicate values. For example, there are two possible values for the
## housing variable: "Rent", "Own" and "ForFree". So that we don't have linear
## dependencies, we get rid of one of the levels (e.g. "ForFree")
GermanCredit <- GermanCredit[, -nearZeroVar(GermanCredit)]
GermanCredit$CheckingAccountStatus.lt.0 <- NULL
GermanCredit$SavingsAccountBonds.lt.100 <- NULL
GermanCredit$EmploymentDuration.lt.1 <- NULL
GermanCredit$EmploymentDuration.Unemployed <- NULL
GermanCredit$Personal.Male.Married.Widowed <- NULL
GermanCredit$Property.Unknown <- NULL
GermanCredit$Housing.ForFree <- NULL
## Split the data into training (80%) and test sets (20%)
set.seed(100)
inTrain <- createDataPartition(GermanCredit$Class, p = .8)[[1]]
GermanCreditTrain <- GermanCredit[ inTrain, ]
GermanCreditTest  <- GermanCredit[-inTrain, ]
## The model fitting code shown in the computing section is fairly
## simplistic.  For the text we estimate the tuning parameter grid
## up-front and pass it in explicitly. This generally is not needed,
## but was used here so that we could trim the cost values to a
## presentable range and to re-use later with different resampling
## methods.
library(kernlab)
set.seed(231)
sigDist <- sigest(Class ~ ., data = GermanCreditTrain, frac = 1)
svmTuneGrid <- data.frame(sigma = as.vector(sigDist)[1], C = 2^(-2:7))
### Optional: parallel processing can be used via the 'do' packages,
### such as doMC, doMPI etc. We used doMC (not on Windows) to speed
### up the computations.
### WARNING: Be aware of how much memory is needed to parallel
### process. It can very quickly overwhelm the available hardware. We
### estimate the memory usage (VSIZE = total memory size) to be
### 2566M/core.
library(doMC)
registerDoMC(4)
set.seed(1056)
svmFit <- train(Class ~ .,
data = GermanCreditTrain,
method = "svmRadial",
preProc = c("center", "scale"),
tuneGrid = svmTuneGrid,
trControl = trainControl(method = "repeatedcv",
repeats = 5,
classProbs = TRUE))
library(caret)
data(GermanCredit)
GermanCredit <- GermanCredit[, -nearZeroVar(GermanCredit)]
GermanCredit$CheckingAccountStatus.lt.0 <- NULL
GermanCredit$SavingsAccountBonds.lt.100 <- NULL
GermanCredit$EmploymentDuration.lt.1 <- NULL
GermanCredit$EmploymentDuration.Unemployed <- NULL
GermanCredit$Personal.Male.Married.Widowed <- NULL
GermanCredit$Property.Unknown <- NULL
GermanCredit$Housing.ForFree <- NULL
set.seed(100)
inTrain <- createDataPartition(GermanCredit$Class, p = .8)[[1]]
GermanCreditTrain <- GermanCredit[ inTrain, ]
GermanCreditTest  <- GermanCredit[-inTrain, ]
library(caret)
data(GermanCredit)
GermanCredit <- GermanCredit[, -nearZeroVar(GermanCredit)]
GermanCredit$CheckingAccountStatus.lt.0 <- NULL
GermanCredit$SavingsAccountBonds.lt.100 <- NULL
GermanCredit$EmploymentDuration.lt.1 <- NULL
GermanCredit$EmploymentDuration.Unemployed <- NULL
GermanCredit$Personal.Male.Married.Widowed <- NULL
GermanCredit$Property.Unknown <- NULL
GermanCredit$Housing.ForFree <- NULL
## Split the data into training (80%) and test sets (20%)
set.seed(100)
inTrain <- createDataPartition(GermanCredit$Class, p = .8)[[1]]
GermanCreditTrain <- GermanCredit[ inTrain, ]
GermanCreditTest  <- GermanCredit[-inTrain, ]
set.seed(1056)
svmFit <- train(Class ~ ., data = GermanCreditTrain,
method = "svmRadial")
set.seed(1056)
svmFit <- train(Class ~ ., data = GermanCreditTrain, method = "svmRadial", preProc = c("center", "scale"))
set.seed(1056)
svmFit <- train(Class ~ ., data = GermanCreditTrain,
method = "svmRadial"
preProc = c("center", "scale"),
svmFit <- train(Class ~ ., data = GermanCreditTrain,
method = "svmRadial".
preProc = c("center", "scale"),
tuneLength = 10)
svmFit <- train(Class ~ ., data = GermanCreditTrain,
method = "svmRadial",
preProc = c("center", "scale"),
tuneLength = 10)
set.seed(1056)
svmFit <- train(Class ~ .,
data = GermanCreditTrain,
method = "svmRadial",
preProc = c("center",  "scale"),
tuneLength = 10,
trControl = trainControl(method = "repeatedcv",
repeats = 5))
svmFit
predictedClasses <- predict(svmFit, GermanCreditTest)
str(predictedClasses)
predictedProbs = predict(svmFit, newdata = GermanCreditTest, type = "prob")
predictedClasses <- predict(svmFit, GermanCreditTest)
predictedProbs = predict(svmFit, newdata = GermanCreditTest, type = "prob")
predictedProbs = predict(svmFit, newdata = GermanCreditTest, type = "prob" classProbs=True)
predictedProbs = predict(svmFit, newdata = GermanCreditTest, type = "prob" classProbs=True)
predictedProbs = predict(svmFit, newdata = GermanCreditTest, type = "prob", classProbs=True)
predictedProbs = predict(svmFit, newdata = GermanCreditTest, type = "prob", classProbs='True')
predictedProbs = predict(svmFit, newdata = GermanCreditTest, classProbs='True')
set.seed(1056)
logisticReg <- train(Class ~ ., data = GermanCreditTrain,
method = "glm",
trControl = trainControl(
method = "repeatedcv",
repeats = 5))
logisticReg
resamp <- resamples(list(SVM = svmFit, Logistic = logisticReg))
summary(resamp)
modelDifference <- diff(resamp)
modelDifference <- diff(resamp)
summary(modelDifference)
modelDifference <- diff(resamp)
summary(modelDifference)
predictedProbs = predict(svmFit, newdata = GermanCreditTest, type ='prob')
library(e1071)
library(ggplot2)
library(caret)
library(plyr)
load("/home/nitin/Downloads/AppliedPredictiveModeling/data/solubility.RData")
modelDifference <- diff(resamp)
summary(solubility)
d = solubility
load("/home/nitin/Downloads/AppliedPredictiveModeling/data/solubility.RData")
